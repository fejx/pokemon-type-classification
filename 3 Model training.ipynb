{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SPRITE_DIRECTORY = 'sprites'\n",
    "TRAIN_DATA_DIRECTORY = os.path.join(SPRITE_DIRECTORY, 'training')\n",
    "TEST_DATA_DIRECTORY = os.path.join(SPRITE_DIRECTORY, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f'Flowing from {TRAIN_DATA_DIRECTORY}')\n",
    "varying_image_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.05\n",
    ")\n",
    "train_image_generator = varying_image_generator.flow_from_directory(\n",
    "    directory=TRAIN_DATA_DIRECTORY,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='rgba',\n",
    "    save_to_dir='/generated'\n",
    ")\n",
    "print(f'Flowing from {TEST_DATA_DIRECTORY}')\n",
    "constant_image_generator = tensorflow.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "test_image_generator = constant_image_generator.flow_from_directory(\n",
    "    directory=TEST_DATA_DIRECTORY,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=False,\n",
    "    color_mode='rgba',\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_file_count_in_subdirectories_of(directory):\n",
    "    subdirectories = os.listdir(directory)\n",
    "    sum = 0\n",
    "    for subdirectory in subdirectories:\n",
    "        subdirectory_path = os.path.join(directory, subdirectory)\n",
    "        files = os.listdir(subdirectory_path)\n",
    "        file_count = len(files)\n",
    "        sum = sum + file_count\n",
    "    print(f'Found {sum} files in {directory}')\n",
    "    return sum\n",
    "\n",
    "TRAIN_DATA_COUNT = get_file_count_in_subdirectories_of(TRAIN_DATA_DIRECTORY)\n",
    "TEST_DATA_COUNT = get_file_count_in_subdirectories_of(TEST_DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import numpy\n",
    "\n",
    "sample_training_images, labels = next(test_image_generator)\n",
    "class_label = {v:k for k,v in test_image_generator.class_indices.items()}\n",
    "fig, axes = plot.subplots(4, 5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, label, ax in zip(sample_training_images, labels, axes):\n",
    "    ax.set_title(class_label[numpy.argmax(label)])\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plot.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 4)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "snapshot_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./.snapshots\"\n",
    ")\n",
    "\n",
    "EPOCHS = 200\n",
    "STEPS = TRAIN_DATA_COUNT / BATCH_SIZE\n",
    "VALIDATION_STEPS = TEST_DATA_COUNT / BATCH_SIZE\n",
    "\n",
    "history = model.fit_generator(\n",
    "    steps_per_epoch=STEPS,\n",
    "    epochs=EPOCHS,\n",
    "    generator=train_image_generator,\n",
    "    #callbacks=[snapshot_callback],\n",
    "    validation_data=test_image_generator,\n",
    "    validation_steps=VALIDATION_STEPS\n",
    ")\n",
    "print('Done training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "prediction = model.predict(test_image_generator)\n",
    "prediction = numpy.argmax(prediction, axis=1)\n",
    "images, actual = next(test_image_generator)\n",
    "actual = numpy.argmax(actual, axis=1)\n",
    "print(actual)\n",
    "score = metrics.accuracy_score(actual, prediction)\n",
    "print(f'Final Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "\n",
    "LOSS = history.history['loss']\n",
    "LOSS_VALIDATION = history.history['val_loss']\n",
    "\n",
    "ACCURACY = history.history['accuracy']\n",
    "ACCURACY_VALIDATION = history.history['val_accuracy']\n",
    "\n",
    "EPOCHS_RANGE = range(EPOCHS)\n",
    "\n",
    "plot.figure()\n",
    "plot.subplot(1, 2, 1)\n",
    "plot.plot(EPOCHS_RANGE, LOSS, label='Training')\n",
    "plot.plot(EPOCHS_RANGE, LOSS_VALIDATION, label='Test')\n",
    "plot.legend()\n",
    "plot.title('Loss')\n",
    "\n",
    "plot.subplot(1, 2, 2)\n",
    "plot.plot(EPOCHS_RANGE, ACCURACY, label='Training')\n",
    "plot.plot(EPOCHS_RANGE, ACCURACY_VALIDATION, label='Test')\n",
    "plot.legend()\n",
    "plot.title('Accuracy')\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataset is not balanced (i.e. there are more water than grass sprites), the values in the confusion matrix need to be normalized. Otherwise, the calculation will be biased towards the water sprites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "from sklearn import metrics\n",
    "import numpy\n",
    "\n",
    "class_names = ['grass', 'water']\n",
    "confusion_matrix = metrics.confusion_matrix(actual, prediction)\n",
    "normalized_confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=1)[:, numpy.newaxis]\n",
    "plot.imshow(normalized_confusion_matrix)\n",
    "plot.title('Confusion matrix')\n",
    "plot.colorbar()\n",
    "tick_marks = [0, 1]\n",
    "plot.xticks(tick_marks, class_names, rotation=45)\n",
    "plot.yticks(tick_marks, class_names)\n",
    "plot.ylabel('Actual')\n",
    "plot.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "import sklearn.metrics\n",
    "\n",
    "predictions = model.predict(test_image_generator)\n",
    "positive_predictions = predictions[:, 1]\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(actual, positive_predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plot.title(f'ROC (area = {roc_auc})')\n",
    "plot.plot(fpr, tpr)\n",
    "plot.plot([0, 1], [0, 1], ':k')\n",
    "plot.xlabel('False positive')\n",
    "plot.ylabel('True positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pokemon_type_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
